{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Data Ingestion\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "import psycopg2 \n",
    "from psycopg2 import Error\n",
    "import psycopg2.extras as extras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat all CSVs in data file to one df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Data'\n",
    "csv_files = glob.glob(path+\"/*.csv\")\n",
    "\n",
    "df_raw_data = pd.DataFrame()\n",
    "\n",
    "for csv in csv_files:\n",
    "    frame = pd.read_csv(csv)\n",
    "    frame['SourceFile'] = os.path.basename(csv)\n",
    "    df_raw_data = pd.concat([df_raw_data,frame])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean column names for whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data.columns = [c.replace(' ', '') for c in df_raw_data.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data_clean = df_raw_data.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move files to DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL server information\n",
      "{'user': 'postgres', 'channel_binding': 'prefer', 'dbname': 'postgres', 'host': 'localhost', 'port': '5432', 'options': '', 'sslmode': 'prefer', 'sslcompression': '0', 'sslsni': '1', 'ssl_min_protocol_version': 'TLSv1.2', 'gssencmode': 'disable', 'krbsrvname': 'postgres', 'target_session_attrs': 'any'} \n",
      "\n",
      "You are connected to -  ('PostgreSQL 16.3, compiled by Visual C++ build 1938, 64-bit',) \n",
      "\n",
      "PostgreSQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Connect to an existing database\n",
    "    connection = psycopg2.connect(user=os.getenv('POSTGRES_USER'),\n",
    "                                  password=os.getenv('POSTGRES_PASSWORD'),\n",
    "                                  host=os.getenv('POSTGRES_HOST'),\n",
    "                                  port=os.getenv('POSTGRES_PORT'),\n",
    "                                  database=os.getenv('POSTGRES_DATABASE'))\n",
    "\n",
    "    # Create a cursor to perform database operations\n",
    "    cursor = connection.cursor()\n",
    "    # Print PostgreSQL details\n",
    "    print(\"PostgreSQL server information\")\n",
    "    print(connection.get_dsn_parameters(), \"\\n\")\n",
    "    # Executing a SQL query\n",
    "    cursor.execute(\"SELECT version();\")\n",
    "    # Fetch result\n",
    "    record = cursor.fetchone()\n",
    "    print(\"You are connected to - \", record, \"\\n\")\n",
    "\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)\n",
    "finally:\n",
    "    if (connection):\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_values(conn, df, table):\n",
    "  \n",
    "    tuples = [tuple(x) for x in df.to_numpy()]\n",
    "  \n",
    "    cols = ','.join(list(df.columns))\n",
    "    # SQL query to execute\n",
    "    query = \"INSERT INTO %s(%s) VALUES %%s\" % (table, cols)\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        extras.execute_values(cursor, query, tuples)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        conn.rollback()\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    print(\"the dataframe is inserted\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is inserted\n"
     ]
    }
   ],
   "source": [
    "connection = psycopg2.connect(user=os.getenv('POSTGRES_USER'),\n",
    "                                  password=os.getenv('POSTGRES_PASSWORD'),\n",
    "                                  host=os.getenv('POSTGRES_HOST'),\n",
    "                                  port=os.getenv('POSTGRES_PORT'),\n",
    "                                  database=os.getenv('POSTGRES_DATABASE'))\n",
    "\n",
    "execute_values(connection,df_raw_data_clean,'etl.raw_txns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move files to archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'Data'\n",
    "target_dir = 'Data/Old'\n",
    "    \n",
    "file_names = os.listdir(source_dir)\n",
    "    \n",
    "for file_name in file_names:\n",
    "    shutil.move(os.path.join(source_dir, file_name), target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# server = os.getenv('SQL_SERVER')\n",
    "# database = os.getenv('SQL_DATABASE')\n",
    "# cnxn_str = 'DRIVER={SQL Server};server='+server+';Database='+database+';Trusted_Connection=yes;'\n",
    "# cnxn = pyodbc.connect(cnxn_str)\n",
    "# cursor = cnxn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, row in df_raw_data_clean.iterrows():\n",
    "#     cursor.execute(\"Insert into raw_txns (BSBNumber,AccountNumber,TransactionDate,Narration,Cheque,Debit,Credit,Balance,TransactionType,SourceFile) Values (?,?,?,?,?,?,?,?,?,?)\", row.BSBNumber,row.AccountNumber,row.TransactionDate,row.Narration,row.Cheque,row.Debit,row.Credit,row.Balance,row.TransactionType,row.SourceFile)\n",
    "# cnxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor.execut   e(\"EXEC etl.RawToStd\")\n",
    "# cnxn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
